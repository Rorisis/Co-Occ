/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-25 07:57:13,173 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA A40
CUDA_HOME: /hpc2ssd/softwares/cuda/cuda-11.3
NVCC: Build cuda_11.3.r11.3/compiler.29920130_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.8.0
MMCV: 1.4.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.14.0
MMSegmentation: 0.14.1
MMDetection3D: 0.17.1+5e630a3
------------------------------------------------------------

2023-10-25 07:57:15,169 - mmdet - INFO - Distributed training: True
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
2023-10-25 07:57:16,993 - mmdet - INFO - Config:
point_cloud_range = [0, -25.6, -2, 51.2, 25.6, 4.4]
class_names = [
    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck', 'other-vehicle',
    'person', 'bicyclist', 'motorcyclist', 'road', 'parking', 'sidewalk',
    'other-ground', 'building', 'fence', 'vegetation', 'trunk', 'terrain',
    'pole', 'traffic-sign'
]
dataset_type = 'CustomSemanticKITTILssDataset_Scale'
data_root = 'data/SemanticKITTI'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadPointsFromFile', coord_type='LIDAR', load_dim=4, use_dim=4),
    dict(
        type='LoadMultiViewImageFromFiles_SemanticKitti',
        is_train=True,
        data_config=dict(
            input_size=(384, 1280),
            resize=(0, 0),
            rot=(0, 0),
            flip=False,
            crop_h=(0.0, 0.0),
            resize_test=0.0),
        img_norm_cfg=dict(
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True)),
    dict(
        type='CreateDepthFromLiDAR',
        data_root='data/SemanticKITTI',
        dataset='kitti'),
    dict(
        type='LoadSemKittiAnnotation',
        bda_aug_conf=dict(
            rot_lim=(0, 0),
            scale_lim=(1, 1),
            flip_dx_ratio=0,
            flip_dy_ratio=0,
            flip_dz_ratio=0),
        is_train=True,
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
        cls_metas='projects/configs/_base_/semantickitti.yaml'),
    dict(
        type='OccDefaultFormatBundle3D',
        class_names=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ]),
    dict(
        type='Collect3D',
        keys=['img_inputs', 'points', 'gt_occ', 'points_occ'],
        meta_keys=['pc_range', 'occ_size'])
]
test_pipeline = [
    dict(type='LoadPointsFromFile', coord_type='LIDAR', load_dim=4, use_dim=4),
    dict(
        type='LoadMultiViewImageFromFiles_SemanticKitti',
        is_train=False,
        data_config=dict(
            input_size=(384, 1280),
            resize=(0, 0),
            rot=(0, 0),
            flip=False,
            crop_h=(0.0, 0.0),
            resize_test=0.0),
        img_norm_cfg=dict(
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True)),
    dict(
        type='LoadSemKittiAnnotation',
        bda_aug_conf=dict(
            rot_lim=(0, 0),
            scale_lim=(1, 1),
            flip_dx_ratio=0,
            flip_dy_ratio=0,
            flip_dz_ratio=0),
        is_train=False,
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
        cls_metas='projects/configs/_base_/semantickitti.yaml'),
    dict(
        type='OccDefaultFormatBundle3D',
        class_names=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        with_label=False),
    dict(
        type='Collect3D',
        keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
        meta_keys=['pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='CustomSemanticKITTILssDataset_Scale',
        data_root='data/SemanticKITTI',
        ann_file='data/SemanticKITTI/labels',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=4,
                use_dim=4),
            dict(
                type='LoadMultiViewImageFromFiles_SemanticKitti',
                is_train=True,
                data_config=dict(
                    input_size=(384, 1280),
                    resize=(0, 0),
                    rot=(0, 0),
                    flip=False,
                    crop_h=(0.0, 0.0),
                    resize_test=0.0),
                img_norm_cfg=dict(
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True)),
            dict(
                type='CreateDepthFromLiDAR',
                data_root='data/SemanticKITTI',
                dataset='kitti'),
            dict(
                type='LoadSemKittiAnnotation',
                bda_aug_conf=dict(
                    rot_lim=(0, 0),
                    scale_lim=(1, 1),
                    flip_dx_ratio=0,
                    flip_dy_ratio=0,
                    flip_dz_ratio=0),
                is_train=True,
                point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
                cls_metas='projects/configs/_base_/semantickitti.yaml'),
            dict(
                type='OccDefaultFormatBundle3D',
                class_names=[
                    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                    'other-vehicle', 'person', 'bicyclist', 'motorcyclist',
                    'road', 'parking', 'sidewalk', 'other-ground', 'building',
                    'fence', 'vegetation', 'trunk', 'terrain', 'pole',
                    'traffic-sign'
                ]),
            dict(
                type='Collect3D',
                keys=['img_inputs', 'points', 'gt_occ', 'points_occ'],
                meta_keys=['pc_range', 'occ_size'])
        ],
        classes=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        split='train',
        camera_used=['left', 'right'],
        lidar_used=True,
        occ_size=[256, 256, 32],
        pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    val=dict(
        type='CustomSemanticKITTILssDataset_Scale',
        ann_file='data/SemanticKITTI/labels',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=4,
                use_dim=4),
            dict(
                type='LoadMultiViewImageFromFiles_SemanticKitti',
                is_train=False,
                data_config=dict(
                    input_size=(384, 1280),
                    resize=(0, 0),
                    rot=(0, 0),
                    flip=False,
                    crop_h=(0.0, 0.0),
                    resize_test=0.0),
                img_norm_cfg=dict(
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True)),
            dict(
                type='LoadSemKittiAnnotation',
                bda_aug_conf=dict(
                    rot_lim=(0, 0),
                    scale_lim=(1, 1),
                    flip_dx_ratio=0,
                    flip_dy_ratio=0,
                    flip_dz_ratio=0),
                is_train=False,
                point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
                cls_metas='projects/configs/_base_/semantickitti.yaml'),
            dict(
                type='OccDefaultFormatBundle3D',
                class_names=[
                    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                    'other-vehicle', 'person', 'bicyclist', 'motorcyclist',
                    'road', 'parking', 'sidewalk', 'other-ground', 'building',
                    'fence', 'vegetation', 'trunk', 'terrain', 'pole',
                    'traffic-sign'
                ],
                with_label=False),
            dict(
                type='Collect3D',
                keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
                meta_keys=[
                    'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
                ])
        ],
        classes=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR',
        data_root='data/SemanticKITTI',
        split='test',
        camera_used=['left', 'right'],
        lidar_used=True,
        occ_size=[256, 256, 32],
        pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    test=dict(
        type='CustomSemanticKITTILssDataset_Scale',
        data_root='data/SemanticKITTI',
        ann_file='data/SemanticKITTI/labels',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=4,
                use_dim=4),
            dict(
                type='LoadMultiViewImageFromFiles_SemanticKitti',
                is_train=False,
                data_config=dict(
                    input_size=(384, 1280),
                    resize=(0, 0),
                    rot=(0, 0),
                    flip=False,
                    crop_h=(0.0, 0.0),
                    resize_test=0.0),
                img_norm_cfg=dict(
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True)),
            dict(
                type='LoadSemKittiAnnotation',
                bda_aug_conf=dict(
                    rot_lim=(0, 0),
                    scale_lim=(1, 1),
                    flip_dx_ratio=0,
                    flip_dy_ratio=0,
                    flip_dz_ratio=0),
                is_train=False,
                point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
                cls_metas='projects/configs/_base_/semantickitti.yaml'),
            dict(
                type='OccDefaultFormatBundle3D',
                class_names=[
                    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                    'other-vehicle', 'person', 'bicyclist', 'motorcyclist',
                    'road', 'parking', 'sidewalk', 'other-ground', 'building',
                    'fence', 'vegetation', 'trunk', 'terrain', 'pole',
                    'traffic-sign'
                ],
                with_label=False),
            dict(
                type='Collect3D',
                keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
                meta_keys=[
                    'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
                ])
        ],
        classes=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR',
        split='test',
        camera_used=['left', 'right'],
        lidar_used=True,
        occ_size=[256, 256, 32],
        pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    shuffler_sampler=dict(type='DistributedGroupSampler'),
    nonshuffler_sampler=dict(type='DistributedSampler'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=4,
            use_dim=4),
        dict(
            type='LoadMultiViewImageFromFiles_SemanticKitti',
            is_train=False,
            data_config=dict(
                input_size=(384, 1280),
                resize=(0, 0),
                rot=(0, 0),
                flip=False,
                crop_h=(0.0, 0.0),
                resize_test=0.0),
            img_norm_cfg=dict(
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True)),
        dict(
            type='LoadSemKittiAnnotation',
            bda_aug_conf=dict(
                rot_lim=(0, 0),
                scale_lim=(1, 1),
                flip_dx_ratio=0,
                flip_dy_ratio=0,
                flip_dz_ratio=0),
            is_train=False,
            point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
            cls_metas='projects/configs/_base_/semantickitti.yaml'),
        dict(
            type='OccDefaultFormatBundle3D',
            class_names=[
                'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
                'parking', 'sidewalk', 'other-ground', 'building', 'fence',
                'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
            ],
            with_label=False),
        dict(
            type='Collect3D',
            keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
            meta_keys=[
                'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
            ])
    ],
    save_best='semkitti_SSC_mIoU',
    rule='greater')
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/scale_multi_kitti'
load_from = None
resume_from = None
workflow = [('train', 1)]
sync_bn = True
plugin = True
plugin_dir = 'projects/mmdet3d_plugin/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
camera_used = ['left', 'right']
num_class = 20
occ_size = [256, 256, 32]
lss_downsample = [2, 2, 2]
voxel_x = 0.2
voxel_y = 0.2
voxel_z = 0.2
voxel_size = [0.2, 0.2, 0.2]
data_config = dict(
    input_size=(384, 1280),
    resize=(0, 0),
    rot=(0, 0),
    flip=False,
    crop_h=(0.0, 0.0),
    resize_test=0.0)
scale = 8
grid_config = dict(
    xbound=[0, 51.2, 0.4],
    ybound=[-25.6, 25.6, 0.4],
    zbound=[-2, 4.4, 0.4],
    dbound=[2.0, 58.0, 0.5])
numC_Trans = 128
voxel_channels = [128, 256, 512, 1024]
voxel_num_layer = [2, 2, 2, 2]
voxel_strides = [1, 2, 2, 2]
voxel_out_indices = (0, 1, 2, 3)
voxel_out_channels = 192
norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
mask2former_num_queries = 100
mask2former_feat_channel = 192
mask2former_output_channel = 192
mask2former_pos_channel = 64.0
mask2former_num_heads = 6
empty_idx = 0
num_cls = 20
visible_mask = False
cascade_ratio = 2
sample_from_voxel = True
sample_from_img = True
model = dict(
    type='MoEOccupancyScale',
    loss_norm=True,
    voxel_size=[0.2, 0.2, 0.2],
    n_voxels=[256, 256, 32],
    aabb=([0, -25.6, -2], [51.2, 25.6, 4.4]),
    near_far_range=[0.2, 51.2],
    N_samples=64,
    N_rand=2048,
    depth_supervise=True,
    use_nerf_mask=True,
    nerf_sample_view=6,
    squeeze_scale=4,
    scale=8,
    nerf_density=True,
    use_rendering=True,
    test_rendering=False,
    loss_voxel_ce_weight=1.0,
    loss_voxel_sem_scal_weight=1.0,
    loss_voxel_geo_scal_weight=1.0,
    loss_voxel_lovasz_weight=1.0,
    img_backbone=dict(
        pretrained='ckpts/resnet50-0676ba61.pth',
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=0,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=False,
        style='pytorch'),
    img_neck=dict(
        type='SECONDFPN',
        in_channels=[256, 512, 1024, 2048],
        upsample_strides=[0.25, 0.5, 1, 2],
        out_channels=[128, 128, 128, 128]),
    img_view_transformer=dict(
        type='ViewTransformerLiftSplatShootVoxel',
        numC_input=512,
        cam_channels=33,
        scale=8,
        loss_depth_weight=1.0,
        grid_config=dict(
            xbound=[0, 51.2, 0.4],
            ybound=[-25.6, 25.6, 0.4],
            zbound=[-2, 4.4, 0.4],
            dbound=[2.0, 58.0, 0.5]),
        data_config=dict(
            input_size=(384, 1280),
            resize=(0, 0),
            rot=(0, 0),
            flip=False,
            crop_h=(0.0, 0.0),
            resize_test=0.0),
        numC_Trans=128,
        vp_megvii=False),
    pts_voxel_layer=dict(
        max_num_points=20,
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
        voxel_size=[0.1, 0.1, 0.1],
        max_voxels=(90000, 120000)),
    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),
    pts_middle_encoder=dict(
        type='SparseLiDAREnc8x',
        input_channel=4,
        base_channel=16,
        out_channel=128,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        sparse_shape_xyz=[1024, 1024, 128]),
    pts_backbone=dict(
        type='SECOND3D',
        in_channels=[128, 128, 128],
        out_channels=[128, 256, 512],
        layer_nums=[5, 5, 5],
        layer_strides=[1, 2, 4],
        is_cascade=False,
        norm_cfg=dict(type='BN3d', eps=0.001, momentum=0.01),
        conv_cfg=dict(type='Conv3d', kernel=(1, 3, 3), bias=False)),
    pts_neck=dict(
        type='SECOND3DFPN',
        in_channels=[128, 256, 512],
        out_channels=[128, 128, 128],
        upsample_strides=[1, 2, 4],
        norm_cfg=dict(type='BN3d', eps=0.001, momentum=0.01),
        upsample_cfg=dict(type='deconv3d', bias=False),
        extra_conv=dict(type='Conv3d', num_conv=3, bias=False),
        use_conv_for_no_stride=True),
    occ_fuser=dict(type='ConvFuser', in_channels=128, out_channels=128),
    img_bev_encoder_backbone=dict(
        type='OccupancyEncoder',
        num_stage=4,
        in_channels=128,
        block_numbers=[2, 2, 2, 2],
        block_inplanes=[128, 256, 512, 1024],
        block_strides=[1, 2, 2, 2],
        out_indices=(0, 1, 2, 3),
        with_cp=True,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
    img_bev_encoder_neck=dict(
        type='MSDeformAttnPixelDecoder3D',
        strides=[2, 4, 8, 16],
        in_channels=[128, 256, 512, 1024],
        feat_channels=192,
        out_channels=192,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        encoder=dict(
            type='DetrTransformerEncoder',
            num_layers=6,
            transformerlayers=dict(
                type='BaseTransformerLayer',
                attn_cfgs=dict(
                    type='MultiScaleDeformableAttention3D',
                    embed_dims=192,
                    num_heads=8,
                    num_levels=3,
                    num_points=4,
                    im2col_step=64,
                    dropout=0.0,
                    batch_first=False,
                    norm_cfg=None,
                    init_cfg=None),
                ffn_cfgs=dict(embed_dims=192),
                feedforward_channels=768,
                ffn_dropout=0.0,
                operation_order=('self_attn', 'norm', 'ffn', 'norm')),
            init_cfg=None),
        positional_encoding=dict(
            type='SinePositionalEncoding3D', num_feats=64, normalize=True)),
    pts_bbox_head=dict(
        type='Mask2FormerOccHead',
        feat_channels=192,
        out_channels=192,
        num_queries=100,
        num_occupancy_classes=20,
        pooling_attn_mask=True,
        sample_weight_gamma=0.25,
        positional_encoding=dict(
            type='SinePositionalEncoding3D', num_feats=64.0, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=192,
                    num_heads=6,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=192,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True),
                feedforward_channels=1536,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1
            ]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0),
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    train_cfg=dict(
        pts=dict(
            num_points=50176,
            oversample_ratio=3.0,
            importance_sample_ratio=0.75,
            assigner=dict(
                type='MaskHungarianAssigner',
                cls_cost=dict(type='ClassificationCost', weight=2.0),
                mask_cost=dict(
                    type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
                dice_cost=dict(
                    type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
            sampler=dict(type='MaskPseudoSampler'))),
    test_cfg=dict(
        pts=dict(semantic_on=True, panoptic_on=False, instance_on=False)))
ann_file = 'data/SemanticKITTI/labels'
kitti_class_metas = 'projects/configs/_base_/semantickitti.yaml'
bda_aug_conf = dict(
    rot_lim=(0, 0),
    scale_lim=(1, 1),
    flip_dx_ratio=0,
    flip_dy_ratio=0,
    flip_dz_ratio=0)
test_config = dict(
    type='CustomSemanticKITTILssDataset_Scale',
    data_root='data/SemanticKITTI',
    ann_file='data/SemanticKITTI/labels',
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=4,
            use_dim=4),
        dict(
            type='LoadMultiViewImageFromFiles_SemanticKitti',
            is_train=False,
            data_config=dict(
                input_size=(384, 1280),
                resize=(0, 0),
                rot=(0, 0),
                flip=False,
                crop_h=(0.0, 0.0),
                resize_test=0.0),
            img_norm_cfg=dict(
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True)),
        dict(
            type='LoadSemKittiAnnotation',
            bda_aug_conf=dict(
                rot_lim=(0, 0),
                scale_lim=(1, 1),
                flip_dx_ratio=0,
                flip_dy_ratio=0,
                flip_dz_ratio=0),
            is_train=False,
            point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
            cls_metas='projects/configs/_base_/semantickitti.yaml'),
        dict(
            type='OccDefaultFormatBundle3D',
            class_names=[
                'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
                'parking', 'sidewalk', 'other-ground', 'building', 'fence',
                'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
            ],
            with_label=False),
        dict(
            type='Collect3D',
            keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
            meta_keys=[
                'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
            ])
    ],
    classes=[
        'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck', 'other-vehicle',
        'person', 'bicyclist', 'motorcyclist', 'road', 'parking', 'sidewalk',
        'other-ground', 'building', 'fence', 'vegetation', 'trunk', 'terrain',
        'pole', 'traffic-sign'
    ],
    modality=dict(
        use_lidar=True,
        use_camera=True,
        use_radar=False,
        use_map=False,
        use_external=False),
    split='test',
    camera_used=['left', 'right'],
    lidar_used=True,
    occ_size=[256, 256, 32],
    pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4])
embed_multi = dict(lr_mult=1.0, decay_mult=0.0)
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    weight_decay=0.01,
    eps=1e-08,
    betas=(0.9, 0.999),
    paramwise_cfg=dict(
        custom_keys=dict(
            query_embed=dict(lr_mult=1.0, decay_mult=0.0),
            query_feat=dict(lr_mult=1.0, decay_mult=0.0),
            level_embed=dict(lr_mult=1.0, decay_mult=0.0),
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0)),
        norm_decay_mult=0.0))
optimizer_config = dict(grad_clip=dict(max_norm=20, norm_type=2))
lr_config = dict(policy='step', step=[20, 25])
runner = dict(type='EpochBasedRunner', max_epochs=30)
gpu_ids = range(0, 8)

2023-10-25 07:57:16,995 - mmdet - INFO - Set random seed to 0, deterministic: False
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-25 07:57:18,267 - mmdet - INFO - initialize SECOND3D with init_cfg {'type': 'Kaiming', 'layer': 'Conv3d'}
2023-10-25 07:57:18,361 - mmdet - INFO - initialize SECOND3DFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
2023-10-25 07:57:18,412 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'ckpts/resnet50-0676ba61.pth'}
2023-10-25 07:57:18,412 - mmcv - INFO - load model from: ckpts/resnet50-0676ba61.pth
2023-10-25 07:57:18,412 - mmcv - INFO - load checkpoint from local path: ckpts/resnet50-0676ba61.pth
2023-10-25 07:57:19,211 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2023-10-25 07:57:19,230 - mmdet - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
2023-10-25 07:57:19,330 - mmdet - INFO - Model:
MoEOccupancyScale(
  (pts_voxel_layer): Voxelization(voxel_size=[0.1, 0.1, 0.1], point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4], max_num_points=20, max_voxels=(90000, 120000), deterministic=True)
  (pts_voxel_encoder): HardSimpleVFE()
  (pts_middle_encoder): SparseLiDAREnc8x(
    (conv_input): SparseSequential(
      (0): SubMConv3d(4, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
      (1): GroupNorm(16, 16, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (2): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (conv2): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (2): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (conv3): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (2): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (conv_out): SparseSequential(
      (0): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
      (1): GroupNorm(16, 128, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (pts_backbone): SECOND3D(
    (blocks): ModuleList(
      (0): Sequential(
        (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (7): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (10): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (13): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (16): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
        (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (4): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (7): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (10): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (13): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (16): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv3d(128, 512, kernel_size=(1, 3, 3), stride=(1, 4, 4), padding=(0, 1, 1), bias=False)
        (1): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (4): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (7): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (10): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (13): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (16): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Kaiming', 'layer': 'Conv3d'}
  (pts_neck): SECOND3DFPN(
    (deblocks): ModuleList(
      (0): Sequential(
        (0): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): ConvTranspose3d(256, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): ConvTranspose3d(512, 128, kernel_size=(1, 4, 4), stride=(1, 4, 4), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (extra_blocks): Sequential(
      (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (7): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  (pts_bbox_head): Mask2FormerOccHead(
    (transformer_decoder): DetrTransformerDecoder(
      (layers): ModuleList(
        (0): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (6): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (7): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (8): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (post_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
    (decoder_input_projs): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Identity()
    )
    (decoder_positional_encoding): SinePositionalEncoding3D(num_feats=64.0, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (query_embed): Embedding(100, 192)
    (query_feat): Embedding(100, 192)
    (level_embed): Embedding(3, 192)
    (cls_embed): Linear(in_features=192, out_features=21, bias=True)
    (mask_embed): Sequential(
      (0): Linear(in_features=192, out_features=192, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=192, out_features=192, bias=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=192, out_features=192, bias=True)
    )
    (loss_cls): CrossEntropyLoss()
    (loss_mask): CrossEntropyLoss()
    (loss_dice): DiceLoss()
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'ckpts/resnet50-0676ba61.pth'}
  (img_neck): SECONDFPN(
    (deblocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(512, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): ConvTranspose2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (3): Sequential(
        (0): ConvTranspose2d(2048, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  (img_view_transformer): ViewTransformerLiftSplatShootVoxel(
    (depth_net): DepthNet(
      (reduce_conv): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (context_conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn): SyncBatchNorm(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (depth_mlp): Mlp(
        (fc1): Linear(in_features=33, out_features=512, bias=True)
        (act): ReLU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=512, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (depth_se): SELayer(
        (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (act1): ReLU()
        (conv_expand): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (gate): Sigmoid()
      )
      (context_mlp): Mlp(
        (fc1): Linear(in_features=33, out_features=512, bias=True)
        (act): ReLU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=512, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (context_se): SELayer(
        (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (act1): ReLU()
        (conv_expand): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (gate): Sigmoid()
      )
      (depth_conv): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): ASPP(
          (aspp1): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (aspp2): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (aspp3): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (aspp4): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (global_avg_pool): Sequential(
            (0): AdaptiveAvgPool2d(output_size=(1, 1))
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): ReLU()
          )
          (conv1): Conv2d(2560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (dropout): Dropout(p=0.5, inplace=False)
        )
        (4): DeformConv2dPack(in_channels=512,
        out_channels=512,
        kernel_size=(3, 3),
        stride=(1, 1),
        padding=(1, 1),
        dilation=(1, 1),
        groups=4,
        deform_groups=1,
        bias=False)
        (5): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (img_bev_encoder_backbone): OccupancyEncoder(
    (layers): ModuleList(
      (0): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 128, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=128, out_features=128, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(16, 32, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(16, 32, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 128, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=128, out_features=128, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(16, 32, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(16, 32, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
      (1): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Sequential(
            (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          )
          (input_conv): Sequential(
            (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=256, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=256, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 64, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(256, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=256, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=256, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 64, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(256, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
      (2): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Sequential(
            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (1): GroupNorm(32, 512, eps=1e-05, affine=True)
          )
          (input_conv): Sequential(
            (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 512, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=512, out_features=512, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 128, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 512, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(512, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 512, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=512, out_features=512, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 128, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 512, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(512, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
      (3): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Sequential(
            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
          )
          (input_conv): Sequential(
            (0): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 256, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(1024, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 256, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(1024, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
    )
  )
  (img_bev_encoder_neck): MSDeformAttnPixelDecoder3D(
    (input_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv3d(1024, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
      (1): ConvModule(
        (conv): Conv3d(512, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
      (2): ConvModule(
        (conv): Conv3d(256, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
    )
    (encoder): DetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (postional_encoding): SinePositionalEncoding3D(num_feats=64, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (level_encoding): Embedding(3, 192)
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv3d(128, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
    )
    (output_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
        (activate): ReLU(inplace=True)
      )
    )
    (mask_feature): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  )
  (occ_fuser): ConvFuser(
    (occ_enc): Sequential(
      (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (color_head): MLP(
    (hidden_activation): ReLU()
    (output_activation): Identity()
    (hidden_layers): ModuleList(
      (0): Linear(in_features=192, out_features=256, bias=True)
      (1): Linear(in_features=256, out_features=256, bias=True)
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (posi_encoder): SinusoidalEncoder()
    (output_layer): Linear(in_features=256, out_features=3, bias=True)
  )
  (density_head): Linear(in_features=192, out_features=1, bias=True)
)
2023-10-25 07:57:31,935 - mmdet - INFO - Start running, host: jpan305@gpu3-13, work_dir: /hpc2hdd/home/jpan305/pytorch/MoEOccupancy/work_dirs/scale_multi_kitti
2023-10-25 07:57:31,936 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) OccDistEvalHook                    
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) OccDistEvalHook                    
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) OccDistEvalHook                    
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) OccDistEvalHook                    
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) OccDistEvalHook                    
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2023-10-25 07:57:31,936 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs
2023-10-25 07:57:31,936 - mmdet - INFO - Checkpoints will be saved to /hpc2hdd/home/jpan305/pytorch/MoEOccupancy/work_dirs/scale_multi_kitti by HardDiskBackend.
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/utils/metric_util.py:15: RuntimeWarning: invalid value encountered in true_divide
  return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py:410: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dir_coord_2d = dir_coord_2d * img_inputs[0].shape[-1] // gemo.shape[-2] #img: b, n, c, h, w gemo: b, d, h, w, c
2023-10-25 07:57:43,270 - mmcv - INFO - Reducer buckets have been rebuilt in this iteration.
2023-10-25 07:59:57,333 - mmdet - INFO - Epoch [1][50/2392]	lr: 1.000e-04, eta: 2 days, 9:29:55, time: 2.887, data_time: 0.073, memory: 25545, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 5.1967, d0.loss_mask: 0.7914, d0.loss_dice: 4.4554, d1.loss_cls: 2.8753, d1.loss_mask: 0.8178, d1.loss_dice: 4.4068, d2.loss_cls: 2.4489, d2.loss_mask: 0.8487, d2.loss_dice: 4.4167, d3.loss_cls: 2.4325, d3.loss_mask: 0.8735, d3.loss_dice: 4.4307, d4.loss_cls: 2.4717, d4.loss_mask: 0.9069, d4.loss_dice: 4.4423, d5.loss_cls: 2.6070, d5.loss_mask: 0.9071, d5.loss_dice: 4.4532, d6.loss_cls: 2.7200, d6.loss_mask: 0.9113, d6.loss_dice: 4.4702, d7.loss_cls: 2.8746, d7.loss_mask: 0.9242, d7.loss_dice: 4.4786, d8.loss_cls: 3.0574, d8.loss_mask: 0.9595, d8.loss_dice: 4.4823, point_mean_iou: 0.0335, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 82.6605, grad_norm: 104.7286
2023-10-25 08:02:14,181 - mmdet - INFO - Epoch [1][100/2392]	lr: 1.000e-04, eta: 2 days, 7:58:12, time: 2.737, data_time: 0.010, memory: 25553, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 4.5883, d0.loss_mask: 0.7279, d0.loss_dice: 4.1842, d1.loss_cls: 0.9323, d1.loss_mask: 0.7715, d1.loss_dice: 4.0947, d2.loss_cls: 0.6196, d2.loss_mask: 0.7765, d2.loss_dice: 4.1064, d3.loss_cls: 0.5750, d3.loss_mask: 0.7712, d3.loss_dice: 4.1076, d4.loss_cls: 0.5262, d4.loss_mask: 0.7732, d4.loss_dice: 4.1134, d5.loss_cls: 0.5208, d5.loss_mask: 0.7812, d5.loss_dice: 4.1124, d6.loss_cls: 0.5272, d6.loss_mask: 0.7781, d6.loss_dice: 4.1133, d7.loss_cls: 0.5352, d7.loss_mask: 0.7790, d7.loss_dice: 4.1287, d8.loss_cls: 0.5496, d8.loss_mask: 0.7730, d8.loss_dice: 4.1231, point_mean_iou: 0.1116, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 61.3895, grad_norm: 50.9537
2023-10-25 08:04:30,777 - mmdet - INFO - Epoch [1][150/2392]	lr: 1.000e-04, eta: 2 days, 7:24:04, time: 2.732, data_time: 0.010, memory: 25558, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 3.9757, d0.loss_mask: 0.7366, d0.loss_dice: 3.9772, d1.loss_cls: 0.5610, d1.loss_mask: 0.7733, d1.loss_dice: 3.9078, d2.loss_cls: 0.4127, d2.loss_mask: 0.7842, d2.loss_dice: 3.9167, d3.loss_cls: 0.3995, d3.loss_mask: 0.7876, d3.loss_dice: 3.9224, d4.loss_cls: 0.4002, d4.loss_mask: 0.7862, d4.loss_dice: 3.9189, d5.loss_cls: 0.3895, d5.loss_mask: 0.7906, d5.loss_dice: 3.9138, d6.loss_cls: 0.3975, d6.loss_mask: 0.7886, d6.loss_dice: 3.9202, d7.loss_cls: 0.3970, d7.loss_mask: 0.7946, d7.loss_dice: 3.9207, d8.loss_cls: 0.4077, d8.loss_mask: 0.7857, d8.loss_dice: 3.9279, point_mean_iou: 0.1456, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 57.6940, grad_norm: 40.8103
2023-10-25 08:06:47,337 - mmdet - INFO - Epoch [1][200/2392]	lr: 1.000e-04, eta: 2 days, 7:05:38, time: 2.731, data_time: 0.009, memory: 25558, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 3.4641, d0.loss_mask: 0.7442, d0.loss_dice: 3.8300, d1.loss_cls: 0.4130, d1.loss_mask: 0.7775, d1.loss_dice: 3.8157, d2.loss_cls: 0.3425, d2.loss_mask: 0.7853, d2.loss_dice: 3.8057, d3.loss_cls: 0.3293, d3.loss_mask: 0.7850, d3.loss_dice: 3.8246, d4.loss_cls: 0.3375, d4.loss_mask: 0.7866, d4.loss_dice: 3.8220, d5.loss_cls: 0.3613, d5.loss_mask: 0.7883, d5.loss_dice: 3.8189, d6.loss_cls: 0.3545, d6.loss_mask: 0.7894, d6.loss_dice: 3.8278, d7.loss_cls: 0.3539, d7.loss_mask: 0.7921, d7.loss_dice: 3.8208, d8.loss_cls: 0.3608, d8.loss_mask: 0.7829, d8.loss_dice: 3.8339, point_mean_iou: 0.1670, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 55.7478, grad_norm: 36.0149
2023-10-25 08:09:04,033 - mmdet - INFO - Epoch [1][250/2392]	lr: 1.000e-04, eta: 2 days, 6:54:21, time: 2.734, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 3.1066, d0.loss_mask: 0.7353, d0.loss_dice: 3.8032, d1.loss_cls: 0.3681, d1.loss_mask: 0.7711, d1.loss_dice: 3.7670, d2.loss_cls: 0.3319, d2.loss_mask: 0.7701, d2.loss_dice: 3.7821, d3.loss_cls: 0.3307, d3.loss_mask: 0.7723, d3.loss_dice: 3.7990, d4.loss_cls: 0.3516, d4.loss_mask: 0.7747, d4.loss_dice: 3.8005, d5.loss_cls: 0.3568, d5.loss_mask: 0.7734, d5.loss_dice: 3.8162, d6.loss_cls: 0.3493, d6.loss_mask: 0.7780, d6.loss_dice: 3.8060, d7.loss_cls: 0.3506, d7.loss_mask: 0.7793, d7.loss_dice: 3.8016, d8.loss_cls: 0.3559, d8.loss_mask: 0.7732, d8.loss_dice: 3.7931, point_mean_iou: 0.1769, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 54.9975, grad_norm: 34.0325
2023-10-25 08:11:20,795 - mmdet - INFO - Epoch [1][300/2392]	lr: 1.000e-04, eta: 2 days, 6:46:18, time: 2.735, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 2.8326, d0.loss_mask: 0.7195, d0.loss_dice: 3.7456, d1.loss_cls: 0.3523, d1.loss_mask: 0.7585, d1.loss_dice: 3.6870, d2.loss_cls: 0.3207, d2.loss_mask: 0.7619, d2.loss_dice: 3.7132, d3.loss_cls: 0.3181, d3.loss_mask: 0.7638, d3.loss_dice: 3.7174, d4.loss_cls: 0.3567, d4.loss_mask: 0.7632, d4.loss_dice: 3.7217, d5.loss_cls: 0.3634, d5.loss_mask: 0.7675, d5.loss_dice: 3.7266, d6.loss_cls: 0.3564, d6.loss_mask: 0.7676, d6.loss_dice: 3.7254, d7.loss_cls: 0.3605, d7.loss_mask: 0.7632, d7.loss_dice: 3.7252, d8.loss_cls: 0.3554, d8.loss_mask: 0.7614, d8.loss_dice: 3.7227, point_mean_iou: 0.1804, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 53.9274, grad_norm: 31.9805
2023-10-25 08:13:37,654 - mmdet - INFO - Epoch [1][350/2392]	lr: 1.000e-04, eta: 2 days, 6:40:15, time: 2.737, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 2.6025, d0.loss_mask: 0.7141, d0.loss_dice: 3.6994, d1.loss_cls: 0.3471, d1.loss_mask: 0.7477, d1.loss_dice: 3.6619, d2.loss_cls: 0.3134, d2.loss_mask: 0.7469, d2.loss_dice: 3.6764, d3.loss_cls: 0.3165, d3.loss_mask: 0.7475, d3.loss_dice: 3.6875, d4.loss_cls: 0.3569, d4.loss_mask: 0.7478, d4.loss_dice: 3.6980, d5.loss_cls: 0.3757, d5.loss_mask: 0.7479, d5.loss_dice: 3.6939, d6.loss_cls: 0.3591, d6.loss_mask: 0.7485, d6.loss_dice: 3.6999, d7.loss_cls: 0.3539, d7.loss_mask: 0.7498, d7.loss_dice: 3.6985, d8.loss_cls: 0.3517, d8.loss_mask: 0.7455, d8.loss_dice: 3.6963, point_mean_iou: 0.1930, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 53.2845, grad_norm: 32.9153
2023-10-25 08:15:54,115 - mmdet - INFO - Epoch [1][400/2392]	lr: 1.000e-04, eta: 2 days, 6:33:57, time: 2.729, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 2.4348, d0.loss_mask: 0.7156, d0.loss_dice: 3.6845, d1.loss_cls: 0.3097, d1.loss_mask: 0.7492, d1.loss_dice: 3.6600, d2.loss_cls: 0.2840, d2.loss_mask: 0.7491, d2.loss_dice: 3.6770, d3.loss_cls: 0.2955, d3.loss_mask: 0.7496, d3.loss_dice: 3.6881, d4.loss_cls: 0.3165, d4.loss_mask: 0.7489, d4.loss_dice: 3.6930, d5.loss_cls: 0.3148, d5.loss_mask: 0.7472, d5.loss_dice: 3.6962, d6.loss_cls: 0.3153, d6.loss_mask: 0.7492, d6.loss_dice: 3.6958, d7.loss_cls: 0.3113, d7.loss_mask: 0.7495, d7.loss_dice: 3.7026, d8.loss_cls: 0.3122, d8.loss_mask: 0.7468, d8.loss_dice: 3.6945, point_mean_iou: 0.1932, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 52.7909, grad_norm: 30.6385
2023-10-25 08:18:10,693 - mmdet - INFO - Epoch [1][450/2392]	lr: 1.000e-04, eta: 2 days, 6:28:51, time: 2.732, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 2.3081, d0.loss_mask: 0.7063, d0.loss_dice: 3.6798, d1.loss_cls: 0.3361, d1.loss_mask: 0.7367, d1.loss_dice: 3.6545, d2.loss_cls: 0.3104, d2.loss_mask: 0.7373, d2.loss_dice: 3.6769, d3.loss_cls: 0.3208, d3.loss_mask: 0.7377, d3.loss_dice: 3.6806, d4.loss_cls: 0.3518, d4.loss_mask: 0.7370, d4.loss_dice: 3.6832, d5.loss_cls: 0.3571, d5.loss_mask: 0.7369, d5.loss_dice: 3.6972, d6.loss_cls: 0.3563, d6.loss_mask: 0.7379, d6.loss_dice: 3.6786, d7.loss_cls: 0.3518, d7.loss_mask: 0.7403, d7.loss_dice: 3.6970, d8.loss_cls: 0.3520, d8.loss_mask: 0.7373, d8.loss_dice: 3.6945, point_mean_iou: 0.1938, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 52.7941, grad_norm: 30.1516
2023-10-25 08:20:27,221 - mmdet - INFO - Epoch [1][500/2392]	lr: 1.000e-04, eta: 2 days, 6:24:12, time: 2.731, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 2.1965, d0.loss_mask: 0.7225, d0.loss_dice: 3.6085, d1.loss_cls: 0.3070, d1.loss_mask: 0.7528, d1.loss_dice: 3.5950, d2.loss_cls: 0.2847, d2.loss_mask: 0.7503, d2.loss_dice: 3.6000, d3.loss_cls: 0.2942, d3.loss_mask: 0.7502, d3.loss_dice: 3.5972, d4.loss_cls: 0.3151, d4.loss_mask: 0.7501, d4.loss_dice: 3.6050, d5.loss_cls: 0.3140, d5.loss_mask: 0.7482, d5.loss_dice: 3.6077, d6.loss_cls: 0.3148, d6.loss_mask: 0.7493, d6.loss_dice: 3.6060, d7.loss_cls: 0.3149, d7.loss_mask: 0.7493, d7.loss_dice: 3.6100, d8.loss_cls: 0.3171, d8.loss_mask: 0.7472, d8.loss_dice: 3.6177, point_mean_iou: 0.2098, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 51.8257, grad_norm: 29.5780
2023-10-25 08:22:43,783 - mmdet - INFO - Epoch [1][550/2392]	lr: 1.000e-04, eta: 2 days, 6:20:03, time: 2.731, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 2.0733, d0.loss_mask: 0.6992, d0.loss_dice: 3.6109, d1.loss_cls: 0.3015, d1.loss_mask: 0.7238, d1.loss_dice: 3.6003, d2.loss_cls: 0.2938, d2.loss_mask: 0.7230, d2.loss_dice: 3.6079, d3.loss_cls: 0.2838, d3.loss_mask: 0.7255, d3.loss_dice: 3.6079, d4.loss_cls: 0.3118, d4.loss_mask: 0.7257, d4.loss_dice: 3.6125, d5.loss_cls: 0.3064, d5.loss_mask: 0.7243, d5.loss_dice: 3.6166, d6.loss_cls: 0.3077, d6.loss_mask: 0.7264, d6.loss_dice: 3.6135, d7.loss_cls: 0.3160, d7.loss_mask: 0.7255, d7.loss_dice: 3.6165, d8.loss_cls: 0.3097, d8.loss_mask: 0.7229, d8.loss_dice: 3.6273, point_mean_iou: 0.2086, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 51.5134, grad_norm: 29.4508
2023-10-25 08:25:00,484 - mmdet - INFO - Epoch [1][600/2392]	lr: 1.000e-04, eta: 2 days, 6:16:30, time: 2.734, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.9453, d0.loss_mask: 0.6988, d0.loss_dice: 3.6054, d1.loss_cls: 0.2913, d1.loss_mask: 0.7247, d1.loss_dice: 3.5909, d2.loss_cls: 0.2811, d2.loss_mask: 0.7232, d2.loss_dice: 3.5982, d3.loss_cls: 0.3019, d3.loss_mask: 0.7223, d3.loss_dice: 3.5974, d4.loss_cls: 0.3008, d4.loss_mask: 0.7239, d4.loss_dice: 3.5978, d5.loss_cls: 0.2965, d5.loss_mask: 0.7203, d5.loss_dice: 3.6055, d6.loss_cls: 0.2878, d6.loss_mask: 0.7206, d6.loss_dice: 3.5998, d7.loss_cls: 0.3020, d7.loss_mask: 0.7196, d7.loss_dice: 3.6036, d8.loss_cls: 0.3065, d8.loss_mask: 0.7195, d8.loss_dice: 3.6051, point_mean_iou: 0.2086, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 51.1899, grad_norm: 29.9669
2023-10-25 08:27:16,975 - mmdet - INFO - Epoch [1][650/2392]	lr: 1.000e-04, eta: 2 days, 6:12:45, time: 2.730, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.8382, d0.loss_mask: 0.7019, d0.loss_dice: 3.6014, d1.loss_cls: 0.2744, d1.loss_mask: 0.7260, d1.loss_dice: 3.5704, d2.loss_cls: 0.2636, d2.loss_mask: 0.7250, d2.loss_dice: 3.5675, d3.loss_cls: 0.2691, d3.loss_mask: 0.7242, d3.loss_dice: 3.5778, d4.loss_cls: 0.2724, d4.loss_mask: 0.7255, d4.loss_dice: 3.5700, d5.loss_cls: 0.2737, d5.loss_mask: 0.7267, d5.loss_dice: 3.5685, d6.loss_cls: 0.2728, d6.loss_mask: 0.7245, d6.loss_dice: 3.5666, d7.loss_cls: 0.2655, d7.loss_mask: 0.7281, d7.loss_dice: 3.5675, d8.loss_cls: 0.2700, d8.loss_mask: 0.7250, d8.loss_dice: 3.5766, point_mean_iou: 0.2159, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 50.6729, grad_norm: 31.0416
2023-10-25 08:29:34,086 - mmdet - INFO - Epoch [1][700/2392]	lr: 1.000e-04, eta: 2 days, 6:10:16, time: 2.742, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.7186, d0.loss_mask: 0.7092, d0.loss_dice: 3.5656, d1.loss_cls: 0.2870, d1.loss_mask: 0.7317, d1.loss_dice: 3.5291, d2.loss_cls: 0.2675, d2.loss_mask: 0.7285, d2.loss_dice: 3.5349, d3.loss_cls: 0.2781, d3.loss_mask: 0.7306, d3.loss_dice: 3.5394, d4.loss_cls: 0.2757, d4.loss_mask: 0.7292, d4.loss_dice: 3.5340, d5.loss_cls: 0.2657, d5.loss_mask: 0.7294, d5.loss_dice: 3.5413, d6.loss_cls: 0.2789, d6.loss_mask: 0.7315, d6.loss_dice: 3.5277, d7.loss_cls: 0.2762, d7.loss_mask: 0.7322, d7.loss_dice: 3.5308, d8.loss_cls: 0.2731, d8.loss_mask: 0.7324, d8.loss_dice: 3.5359, point_mean_iou: 0.2205, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 50.3146, grad_norm: 29.5368
2023-10-25 08:31:50,560 - mmdet - INFO - Epoch [1][750/2392]	lr: 1.000e-04, eta: 2 days, 6:06:48, time: 2.729, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.6472, d0.loss_mask: 0.6935, d0.loss_dice: 3.5312, d1.loss_cls: 0.2764, d1.loss_mask: 0.7184, d1.loss_dice: 3.4956, d2.loss_cls: 0.2617, d2.loss_mask: 0.7158, d2.loss_dice: 3.4873, d3.loss_cls: 0.2704, d3.loss_mask: 0.7152, d3.loss_dice: 3.4914, d4.loss_cls: 0.2622, d4.loss_mask: 0.7159, d4.loss_dice: 3.4883, d5.loss_cls: 0.2552, d5.loss_mask: 0.7156, d5.loss_dice: 3.4981, d6.loss_cls: 0.2691, d6.loss_mask: 0.7142, d6.loss_dice: 3.4866, d7.loss_cls: 0.2661, d7.loss_mask: 0.7124, d7.loss_dice: 3.4910, d8.loss_cls: 0.2664, d8.loss_mask: 0.7109, d8.loss_dice: 3.4976, point_mean_iou: 0.2226, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 49.6536, grad_norm: 30.1248
2023-10-25 08:34:07,012 - mmdet - INFO - Epoch [1][800/2392]	lr: 1.000e-04, eta: 2 days, 6:03:26, time: 2.729, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.5544, d0.loss_mask: 0.6933, d0.loss_dice: 3.5010, d1.loss_cls: 0.2653, d1.loss_mask: 0.7174, d1.loss_dice: 3.4547, d2.loss_cls: 0.2485, d2.loss_mask: 0.7151, d2.loss_dice: 3.4561, d3.loss_cls: 0.2632, d3.loss_mask: 0.7126, d3.loss_dice: 3.4535, d4.loss_cls: 0.2624, d4.loss_mask: 0.7144, d4.loss_dice: 3.4537, d5.loss_cls: 0.2523, d5.loss_mask: 0.7130, d5.loss_dice: 3.4597, d6.loss_cls: 0.2559, d6.loss_mask: 0.7140, d6.loss_dice: 3.4589, d7.loss_cls: 0.2552, d7.loss_mask: 0.7152, d7.loss_dice: 3.4583, d8.loss_cls: 0.2516, d8.loss_mask: 0.7132, d8.loss_dice: 3.4610, point_mean_iou: 0.2362, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 49.1741, grad_norm: 29.7995
2023-10-25 08:36:23,928 - mmdet - INFO - Epoch [1][850/2392]	lr: 1.000e-04, eta: 2 days, 6:00:53, time: 2.738, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.4298, d0.loss_mask: 0.6877, d0.loss_dice: 3.5232, d1.loss_cls: 0.2346, d1.loss_mask: 0.7104, d1.loss_dice: 3.4727, d2.loss_cls: 0.2373, d2.loss_mask: 0.7108, d2.loss_dice: 3.4664, d3.loss_cls: 0.2268, d3.loss_mask: 0.7105, d3.loss_dice: 3.4730, d4.loss_cls: 0.2235, d4.loss_mask: 0.7116, d4.loss_dice: 3.4766, d5.loss_cls: 0.2199, d5.loss_mask: 0.7078, d5.loss_dice: 3.4825, d6.loss_cls: 0.2304, d6.loss_mask: 0.7098, d6.loss_dice: 3.4703, d7.loss_cls: 0.2257, d7.loss_mask: 0.7093, d7.loss_dice: 3.4790, d8.loss_cls: 0.2387, d8.loss_mask: 0.7060, d8.loss_dice: 3.4772, point_mean_iou: 0.2364, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 48.9514, grad_norm: 29.7275
2023-10-25 08:38:40,667 - mmdet - INFO - Epoch [1][900/2392]	lr: 1.000e-04, eta: 2 days, 5:58:06, time: 2.735, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.3657, d0.loss_mask: 0.6854, d0.loss_dice: 3.5180, d1.loss_cls: 0.2693, d1.loss_mask: 0.7061, d1.loss_dice: 3.4751, d2.loss_cls: 0.2565, d2.loss_mask: 0.7050, d2.loss_dice: 3.4711, d3.loss_cls: 0.2564, d3.loss_mask: 0.7054, d3.loss_dice: 3.4695, d4.loss_cls: 0.2561, d4.loss_mask: 0.7039, d4.loss_dice: 3.4726, d5.loss_cls: 0.2609, d5.loss_mask: 0.7024, d5.loss_dice: 3.4744, d6.loss_cls: 0.2589, d6.loss_mask: 0.7018, d6.loss_dice: 3.4718, d7.loss_cls: 0.2610, d7.loss_mask: 0.7031, d7.loss_dice: 3.4706, d8.loss_cls: 0.2659, d8.loss_mask: 0.7003, d8.loss_dice: 3.4790, point_mean_iou: 0.2300, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 49.0661, grad_norm: 31.2230
2023-10-25 08:40:57,050 - mmdet - INFO - Epoch [1][950/2392]	lr: 1.000e-04, eta: 2 days, 5:54:56, time: 2.728, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.3126, d0.loss_mask: 0.6943, d0.loss_dice: 3.4326, d1.loss_cls: 0.2544, d1.loss_mask: 0.7110, d1.loss_dice: 3.4071, d2.loss_cls: 0.2611, d2.loss_mask: 0.7078, d2.loss_dice: 3.4016, d3.loss_cls: 0.2461, d3.loss_mask: 0.7067, d3.loss_dice: 3.4058, d4.loss_cls: 0.2506, d4.loss_mask: 0.7080, d4.loss_dice: 3.4037, d5.loss_cls: 0.2530, d5.loss_mask: 0.7085, d5.loss_dice: 3.4003, d6.loss_cls: 0.2568, d6.loss_mask: 0.7046, d6.loss_dice: 3.4000, d7.loss_cls: 0.2497, d7.loss_mask: 0.7064, d7.loss_dice: 3.3969, d8.loss_cls: 0.2554, d8.loss_mask: 0.7045, d8.loss_dice: 3.4039, point_mean_iou: 0.2481, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 48.3436, grad_norm: 32.2430
2023-10-25 08:43:13,671 - mmdet - INFO - Exp name: scale_multi_kitti.py
2023-10-25 08:43:13,671 - mmdet - INFO - Epoch [1][1000/2392]	lr: 1.000e-04, eta: 2 days, 5:52:08, time: 2.732, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.2189, d0.loss_mask: 0.6830, d0.loss_dice: 3.4254, d1.loss_cls: 0.2584, d1.loss_mask: 0.6965, d1.loss_dice: 3.4174, d2.loss_cls: 0.2458, d2.loss_mask: 0.6971, d2.loss_dice: 3.4043, d3.loss_cls: 0.2448, d3.loss_mask: 0.6938, d3.loss_dice: 3.4107, d4.loss_cls: 0.2419, d4.loss_mask: 0.6964, d4.loss_dice: 3.4129, d5.loss_cls: 0.2407, d5.loss_mask: 0.6932, d5.loss_dice: 3.4153, d6.loss_cls: 0.2591, d6.loss_mask: 0.6930, d6.loss_dice: 3.4059, d7.loss_cls: 0.2578, d7.loss_mask: 0.6941, d7.loss_dice: 3.4035, d8.loss_cls: 0.2587, d8.loss_mask: 0.6936, d8.loss_dice: 3.4146, point_mean_iou: 0.2486, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 48.1767, grad_norm: 31.6492
2023-10-25 08:45:30,617 - mmdet - INFO - Epoch [1][1050/2392]	lr: 1.000e-04, eta: 2 days, 5:49:45, time: 2.739, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.1598, d0.loss_mask: 0.6835, d0.loss_dice: 3.4237, d1.loss_cls: 0.2431, d1.loss_mask: 0.6959, d1.loss_dice: 3.4019, d2.loss_cls: 0.2392, d2.loss_mask: 0.6962, d2.loss_dice: 3.3930, d3.loss_cls: 0.2244, d3.loss_mask: 0.6927, d3.loss_dice: 3.3973, d4.loss_cls: 0.2247, d4.loss_mask: 0.6932, d4.loss_dice: 3.3910, d5.loss_cls: 0.2213, d5.loss_mask: 0.6929, d5.loss_dice: 3.3960, d6.loss_cls: 0.2179, d6.loss_mask: 0.6926, d6.loss_dice: 3.3989, d7.loss_cls: 0.2191, d7.loss_mask: 0.6917, d7.loss_dice: 3.3930, d8.loss_cls: 0.2058, d8.loss_mask: 0.6909, d8.loss_dice: 3.3987, point_mean_iou: 0.2533, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 47.7784, grad_norm: 33.7433
2023-10-25 08:47:47,326 - mmdet - INFO - Epoch [1][1100/2392]	lr: 1.000e-04, eta: 2 days, 5:47:08, time: 2.734, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.0919, d0.loss_mask: 0.6897, d0.loss_dice: 3.4296, d1.loss_cls: 0.2573, d1.loss_mask: 0.7026, d1.loss_dice: 3.4197, d2.loss_cls: 0.2490, d2.loss_mask: 0.7033, d2.loss_dice: 3.4150, d3.loss_cls: 0.2444, d3.loss_mask: 0.7018, d3.loss_dice: 3.4181, d4.loss_cls: 0.2418, d4.loss_mask: 0.6991, d4.loss_dice: 3.4188, d5.loss_cls: 0.2493, d5.loss_mask: 0.7010, d5.loss_dice: 3.4198, d6.loss_cls: 0.2392, d6.loss_mask: 0.6992, d6.loss_dice: 3.4240, d7.loss_cls: 0.2345, d7.loss_mask: 0.7008, d7.loss_dice: 3.4179, d8.loss_cls: 0.2335, d8.loss_mask: 0.7011, d8.loss_dice: 3.4222, point_mean_iou: 0.2541, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 48.1247, grad_norm: 32.2350
2023-10-25 08:50:03,675 - mmdet - INFO - Epoch [1][1150/2392]	lr: 1.000e-04, eta: 2 days, 5:44:10, time: 2.727, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 1.0262, d0.loss_mask: 0.6981, d0.loss_dice: 3.3885, d1.loss_cls: 0.2354, d1.loss_mask: 0.7098, d1.loss_dice: 3.3788, d2.loss_cls: 0.2334, d2.loss_mask: 0.7083, d2.loss_dice: 3.3772, d3.loss_cls: 0.2186, d3.loss_mask: 0.7065, d3.loss_dice: 3.3746, d4.loss_cls: 0.2268, d4.loss_mask: 0.7103, d4.loss_dice: 3.3679, d5.loss_cls: 0.2129, d5.loss_mask: 0.7082, d5.loss_dice: 3.3722, d6.loss_cls: 0.2119, d6.loss_mask: 0.7081, d6.loss_dice: 3.3680, d7.loss_cls: 0.2176, d7.loss_mask: 0.7079, d7.loss_dice: 3.3712, d8.loss_cls: 0.2107, d8.loss_mask: 0.7047, d8.loss_dice: 3.3757, point_mean_iou: 0.2619, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 47.5295, grad_norm: 34.3441
2023-10-25 08:52:20,414 - mmdet - INFO - Epoch [1][1200/2392]	lr: 1.000e-04, eta: 2 days, 5:41:38, time: 2.735, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.9925, d0.loss_mask: 0.6803, d0.loss_dice: 3.3655, d1.loss_cls: 0.2504, d1.loss_mask: 0.6971, d1.loss_dice: 3.3463, d2.loss_cls: 0.2420, d2.loss_mask: 0.6946, d2.loss_dice: 3.3416, d3.loss_cls: 0.2319, d3.loss_mask: 0.6949, d3.loss_dice: 3.3392, d4.loss_cls: 0.2243, d4.loss_mask: 0.6935, d4.loss_dice: 3.3435, d5.loss_cls: 0.2180, d5.loss_mask: 0.6930, d5.loss_dice: 3.3447, d6.loss_cls: 0.2161, d6.loss_mask: 0.6956, d6.loss_dice: 3.3447, d7.loss_cls: 0.2135, d7.loss_mask: 0.6941, d7.loss_dice: 3.3391, d8.loss_cls: 0.2152, d8.loss_mask: 0.6931, d8.loss_dice: 3.3413, point_mean_iou: 0.2640, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 47.1463, grad_norm: 33.1850
2023-10-25 08:54:37,191 - mmdet - INFO - Epoch [1][1250/2392]	lr: 1.000e-04, eta: 2 days, 5:39:10, time: 2.736, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.9433, d0.loss_mask: 0.6626, d0.loss_dice: 3.3679, d1.loss_cls: 0.2588, d1.loss_mask: 0.6764, d1.loss_dice: 3.3547, d2.loss_cls: 0.2564, d2.loss_mask: 0.6750, d2.loss_dice: 3.3529, d3.loss_cls: 0.2455, d3.loss_mask: 0.6736, d3.loss_dice: 3.3538, d4.loss_cls: 0.2494, d4.loss_mask: 0.6763, d4.loss_dice: 3.3510, d5.loss_cls: 0.2268, d5.loss_mask: 0.6744, d5.loss_dice: 3.3647, d6.loss_cls: 0.2382, d6.loss_mask: 0.6742, d6.loss_dice: 3.3511, d7.loss_cls: 0.2401, d7.loss_mask: 0.6749, d7.loss_dice: 3.3458, d8.loss_cls: 0.2302, d8.loss_mask: 0.6724, d8.loss_dice: 3.3559, point_mean_iou: 0.2574, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 47.1462, grad_norm: 33.3424
2023-10-25 08:56:53,867 - mmdet - INFO - Epoch [1][1300/2392]	lr: 1.000e-04, eta: 2 days, 5:36:38, time: 2.734, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.8550, d0.loss_mask: 0.6751, d0.loss_dice: 3.3995, d1.loss_cls: 0.2412, d1.loss_mask: 0.6885, d1.loss_dice: 3.3740, d2.loss_cls: 0.2413, d2.loss_mask: 0.6865, d2.loss_dice: 3.3688, d3.loss_cls: 0.2392, d3.loss_mask: 0.6850, d3.loss_dice: 3.3658, d4.loss_cls: 0.2326, d4.loss_mask: 0.6865, d4.loss_dice: 3.3728, d5.loss_cls: 0.2190, d5.loss_mask: 0.6849, d5.loss_dice: 3.3706, d6.loss_cls: 0.2131, d6.loss_mask: 0.6871, d6.loss_dice: 3.3702, d7.loss_cls: 0.2129, d7.loss_mask: 0.6860, d7.loss_dice: 3.3697, d8.loss_cls: 0.2228, d8.loss_mask: 0.6866, d8.loss_dice: 3.3757, point_mean_iou: 0.2673, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 47.2106, grad_norm: 34.8101
2023-10-25 08:59:10,499 - mmdet - INFO - Epoch [1][1350/2392]	lr: 1.000e-04, eta: 2 days, 5:34:04, time: 2.733, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.8139, d0.loss_mask: 0.6734, d0.loss_dice: 3.3326, d1.loss_cls: 0.2322, d1.loss_mask: 0.6863, d1.loss_dice: 3.3180, d2.loss_cls: 0.2342, d2.loss_mask: 0.6851, d2.loss_dice: 3.3083, d3.loss_cls: 0.2185, d3.loss_mask: 0.6843, d3.loss_dice: 3.3143, d4.loss_cls: 0.2158, d4.loss_mask: 0.6828, d4.loss_dice: 3.3164, d5.loss_cls: 0.2121, d5.loss_mask: 0.6836, d5.loss_dice: 3.3195, d6.loss_cls: 0.2065, d6.loss_mask: 0.6852, d6.loss_dice: 3.3121, d7.loss_cls: 0.2027, d7.loss_mask: 0.6827, d7.loss_dice: 3.3127, d8.loss_cls: 0.2048, d8.loss_mask: 0.6817, d8.loss_dice: 3.3201, point_mean_iou: 0.2707, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 46.5397, grad_norm: 32.5366
2023-10-25 09:01:27,353 - mmdet - INFO - Epoch [1][1400/2392]	lr: 1.000e-04, eta: 2 days, 5:31:42, time: 2.737, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.7790, d0.loss_mask: 0.6640, d0.loss_dice: 3.3021, d1.loss_cls: 0.2374, d1.loss_mask: 0.6731, d1.loss_dice: 3.2846, d2.loss_cls: 0.2159, d2.loss_mask: 0.6721, d2.loss_dice: 3.2800, d3.loss_cls: 0.2141, d3.loss_mask: 0.6719, d3.loss_dice: 3.2742, d4.loss_cls: 0.2114, d4.loss_mask: 0.6696, d4.loss_dice: 3.2782, d5.loss_cls: 0.1998, d5.loss_mask: 0.6714, d5.loss_dice: 3.2785, d6.loss_cls: 0.1950, d6.loss_mask: 0.6706, d6.loss_dice: 3.2785, d7.loss_cls: 0.1968, d7.loss_mask: 0.6712, d7.loss_dice: 3.2815, d8.loss_cls: 0.2016, d8.loss_mask: 0.6701, d8.loss_dice: 3.2796, point_mean_iou: 0.2760, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 46.0223, grad_norm: 32.6277
2023-10-25 09:03:44,184 - mmdet - INFO - Epoch [1][1450/2392]	lr: 1.000e-04, eta: 2 days, 5:29:20, time: 2.737, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.7296, d0.loss_mask: 0.6618, d0.loss_dice: 3.3353, d1.loss_cls: 0.2359, d1.loss_mask: 0.6716, d1.loss_dice: 3.3157, d2.loss_cls: 0.2393, d2.loss_mask: 0.6696, d2.loss_dice: 3.3068, d3.loss_cls: 0.2232, d3.loss_mask: 0.6694, d3.loss_dice: 3.3156, d4.loss_cls: 0.2231, d4.loss_mask: 0.6740, d4.loss_dice: 3.3136, d5.loss_cls: 0.2158, d5.loss_mask: 0.6738, d5.loss_dice: 3.3128, d6.loss_cls: 0.2014, d6.loss_mask: 0.6729, d6.loss_dice: 3.3115, d7.loss_cls: 0.2070, d7.loss_mask: 0.6729, d7.loss_dice: 3.3150, d8.loss_cls: 0.2108, d8.loss_mask: 0.6716, d8.loss_dice: 3.3199, point_mean_iou: 0.2718, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 46.3699, grad_norm: 32.2411
2023-10-25 09:06:00,752 - mmdet - INFO - Epoch [1][1500/2392]	lr: 1.000e-04, eta: 2 days, 5:26:46, time: 2.731, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.7237, d0.loss_mask: 0.6695, d0.loss_dice: 3.2841, d1.loss_cls: 0.2396, d1.loss_mask: 0.6786, d1.loss_dice: 3.2691, d2.loss_cls: 0.2324, d2.loss_mask: 0.6766, d2.loss_dice: 3.2651, d3.loss_cls: 0.2181, d3.loss_mask: 0.6758, d3.loss_dice: 3.2666, d4.loss_cls: 0.2178, d4.loss_mask: 0.6750, d4.loss_dice: 3.2684, d5.loss_cls: 0.2198, d5.loss_mask: 0.6764, d5.loss_dice: 3.2650, d6.loss_cls: 0.2061, d6.loss_mask: 0.6781, d6.loss_dice: 3.2617, d7.loss_cls: 0.2038, d7.loss_mask: 0.6778, d7.loss_dice: 3.2695, d8.loss_cls: 0.2127, d8.loss_mask: 0.6776, d8.loss_dice: 3.2614, point_mean_iou: 0.2737, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 45.9704, grad_norm: 34.1452
2023-10-25 09:08:17,604 - mmdet - INFO - Epoch [1][1550/2392]	lr: 1.000e-04, eta: 2 days, 5:24:26, time: 2.737, data_time: 0.009, memory: 25574, loss_depth: 1.0000, loss_cls: 1.0000, loss_mask: 1.0000, loss_dice: 1.0000, d0.loss_cls: 0.6845, d0.loss_mask: 0.6623, d0.loss_dice: 3.2512, d1.loss_cls: 0.2259, d1.loss_mask: 0.6701, d1.loss_dice: 3.2422, d2.loss_cls: 0.2133, d2.loss_mask: 0.6715, d2.loss_dice: 3.2335, d3.loss_cls: 0.2085, d3.loss_mask: 0.6709, d3.loss_dice: 3.2321, d4.loss_cls: 0.2059, d4.loss_mask: 0.6725, d4.loss_dice: 3.2354, d5.loss_cls: 0.2026, d5.loss_mask: 0.6734, d5.loss_dice: 3.2407, d6.loss_cls: 0.2012, d6.loss_mask: 0.6741, d6.loss_dice: 3.2344, d7.loss_cls: 0.2076, d7.loss_mask: 0.6702, d7.loss_dice: 3.2373, d8.loss_cls: 0.2056, d8.loss_mask: 0.6706, d8.loss_dice: 3.2428, point_mean_iou: 0.2818, loss_lidarseg: 1.0000, loss_color: 1.0000, loss_render_depth: 1.0000, loss_opacity: 1.0000, loss: 45.5402, grad_norm: 34.2284
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
    runner.run(data_loaders, cfg.workflow)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 47, in train
    for i, data_batch in enumerate(self.data_loader):
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/datasets/semantic_kitti_lss_dataset.py", line 443, in __getitem__
    data = self.prepare_train_data(idx)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/datasets/semantic_kitti_lss_dataset.py", line 435, in prepare_train_data
    example = self.pipeline(input_dict)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/mmdet/datasets/pipelines/compose.py", line 40, in __call__
    data = t(data)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/datasets/pipelines/loading_kitti_occ.py", line 66, in __call__
    lidarseg = np.concatenate([points, sem_labels], axis=-1)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 57344 and the array at index 1 has size 124854

WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995196 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995197 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995198 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995199 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995200 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995201 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1995202 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1995195) of binary: /hpc2hdd/home/jpan305/miniconda3/envs/openocc/bin/python
Traceback (most recent call last):
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/run.py", line 713, in run
    )(*cmd_args)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/hpc2hdd/home/jpan305/miniconda3/envs/openocc/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 261, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
tools/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-25_09:09:12
  host      : gpu3-13.hkust-gz.edu.cn
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1995195)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
