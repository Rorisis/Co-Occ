/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-28 00:30:17,691 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.0 (default, Oct  9 2018, 10:31:47) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA A800-SXM4-80GB
CUDA_HOME: /hpc2ssd/softwares/cuda/cuda-11.3
NVCC: Build cuda_11.3.r11.3/compiler.29920130_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.8.0
MMCV: 1.4.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.14.0
MMSegmentation: 0.14.1
MMDetection3D: 0.17.1+72a5322
------------------------------------------------------------

2023-10-28 00:30:19,578 - mmdet - INFO - Distributed training: True
2023-10-28 00:30:21,406 - mmdet - INFO - Config:
point_cloud_range = [0, -25.6, -2, 51.2, 25.6, 4.4]
class_names = [
    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck', 'other-vehicle',
    'person', 'bicyclist', 'motorcyclist', 'road', 'parking', 'sidewalk',
    'other-ground', 'building', 'fence', 'vegetation', 'trunk', 'terrain',
    'pole', 'traffic-sign'
]
dataset_type = 'CustomSemanticKITTILssDataset_Scale'
data_root = 'data/SemanticKITTI'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadPointsFromFile', coord_type='LIDAR', load_dim=4, use_dim=4),
    dict(
        type='LoadMultiViewImageFromFiles_SemanticKitti',
        is_train=True,
        data_config=dict(
            input_size=(384, 1280),
            resize=(0, 0),
            rot=(0, 0),
            flip=False,
            crop_h=(0.0, 0.0),
            resize_test=0.0),
        img_norm_cfg=dict(
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True)),
    dict(
        type='CreateDepthFromLiDAR',
        data_root='data/SemanticKITTI',
        dataset='kitti'),
    dict(
        type='LoadSemKittiAnnotation',
        bda_aug_conf=dict(
            rot_lim=(0, 0),
            scale_lim=(1, 1),
            flip_dx_ratio=0,
            flip_dy_ratio=0,
            flip_dz_ratio=0),
        is_train=True,
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
        cls_metas='projects/configs/_base_/semantickitti.yaml'),
    dict(
        type='OccDefaultFormatBundle3D',
        class_names=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ]),
    dict(
        type='Collect3D',
        keys=['img_inputs', 'points', 'gt_occ', 'points_occ'],
        meta_keys=['pc_range', 'occ_size'])
]
test_pipeline = [
    dict(type='LoadPointsFromFile', coord_type='LIDAR', load_dim=4, use_dim=4),
    dict(
        type='LoadMultiViewImageFromFiles_SemanticKitti',
        is_train=False,
        data_config=dict(
            input_size=(384, 1280),
            resize=(0, 0),
            rot=(0, 0),
            flip=False,
            crop_h=(0.0, 0.0),
            resize_test=0.0),
        img_norm_cfg=dict(
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True)),
    dict(
        type='LoadSemKittiAnnotation',
        bda_aug_conf=dict(
            rot_lim=(0, 0),
            scale_lim=(1, 1),
            flip_dx_ratio=0,
            flip_dy_ratio=0,
            flip_dz_ratio=0),
        is_train=False,
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
        cls_metas='projects/configs/_base_/semantickitti.yaml'),
    dict(
        type='OccDefaultFormatBundle3D',
        class_names=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        with_label=False),
    dict(
        type='Collect3D',
        keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
        meta_keys=['pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='CustomSemanticKITTILssDataset_Scale',
        data_root='data/SemanticKITTI',
        ann_file='data/SemanticKITTI/labels',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=4,
                use_dim=4),
            dict(
                type='LoadMultiViewImageFromFiles_SemanticKitti',
                is_train=True,
                data_config=dict(
                    input_size=(384, 1280),
                    resize=(0, 0),
                    rot=(0, 0),
                    flip=False,
                    crop_h=(0.0, 0.0),
                    resize_test=0.0),
                img_norm_cfg=dict(
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True)),
            dict(
                type='CreateDepthFromLiDAR',
                data_root='data/SemanticKITTI',
                dataset='kitti'),
            dict(
                type='LoadSemKittiAnnotation',
                bda_aug_conf=dict(
                    rot_lim=(0, 0),
                    scale_lim=(1, 1),
                    flip_dx_ratio=0,
                    flip_dy_ratio=0,
                    flip_dz_ratio=0),
                is_train=True,
                point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
                cls_metas='projects/configs/_base_/semantickitti.yaml'),
            dict(
                type='OccDefaultFormatBundle3D',
                class_names=[
                    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                    'other-vehicle', 'person', 'bicyclist', 'motorcyclist',
                    'road', 'parking', 'sidewalk', 'other-ground', 'building',
                    'fence', 'vegetation', 'trunk', 'terrain', 'pole',
                    'traffic-sign'
                ]),
            dict(
                type='Collect3D',
                keys=['img_inputs', 'points', 'gt_occ', 'points_occ'],
                meta_keys=['pc_range', 'occ_size'])
        ],
        classes=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR',
        split='train',
        camera_used=['left', 'right'],
        lidar_used=True,
        occ_size=[256, 256, 32],
        pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    val=dict(
        type='CustomSemanticKITTILssDataset_Scale',
        ann_file='data/SemanticKITTI/labels',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=4,
                use_dim=4),
            dict(
                type='LoadMultiViewImageFromFiles_SemanticKitti',
                is_train=False,
                data_config=dict(
                    input_size=(384, 1280),
                    resize=(0, 0),
                    rot=(0, 0),
                    flip=False,
                    crop_h=(0.0, 0.0),
                    resize_test=0.0),
                img_norm_cfg=dict(
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True)),
            dict(
                type='LoadSemKittiAnnotation',
                bda_aug_conf=dict(
                    rot_lim=(0, 0),
                    scale_lim=(1, 1),
                    flip_dx_ratio=0,
                    flip_dy_ratio=0,
                    flip_dz_ratio=0),
                is_train=False,
                point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
                cls_metas='projects/configs/_base_/semantickitti.yaml'),
            dict(
                type='OccDefaultFormatBundle3D',
                class_names=[
                    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                    'other-vehicle', 'person', 'bicyclist', 'motorcyclist',
                    'road', 'parking', 'sidewalk', 'other-ground', 'building',
                    'fence', 'vegetation', 'trunk', 'terrain', 'pole',
                    'traffic-sign'
                ],
                with_label=False),
            dict(
                type='Collect3D',
                keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
                meta_keys=[
                    'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
                ])
        ],
        classes=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR',
        data_root='data/SemanticKITTI',
        split='test',
        camera_used=['left', 'right'],
        lidar_used=True,
        occ_size=[256, 256, 32],
        pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    test=dict(
        type='CustomSemanticKITTILssDataset_Scale',
        data_root='data/SemanticKITTI',
        ann_file='data/SemanticKITTI/labels',
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=4,
                use_dim=4),
            dict(
                type='LoadMultiViewImageFromFiles_SemanticKitti',
                is_train=False,
                data_config=dict(
                    input_size=(384, 1280),
                    resize=(0, 0),
                    rot=(0, 0),
                    flip=False,
                    crop_h=(0.0, 0.0),
                    resize_test=0.0),
                img_norm_cfg=dict(
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True)),
            dict(
                type='LoadSemKittiAnnotation',
                bda_aug_conf=dict(
                    rot_lim=(0, 0),
                    scale_lim=(1, 1),
                    flip_dx_ratio=0,
                    flip_dy_ratio=0,
                    flip_dz_ratio=0),
                is_train=False,
                point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
                cls_metas='projects/configs/_base_/semantickitti.yaml'),
            dict(
                type='OccDefaultFormatBundle3D',
                class_names=[
                    'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                    'other-vehicle', 'person', 'bicyclist', 'motorcyclist',
                    'road', 'parking', 'sidewalk', 'other-ground', 'building',
                    'fence', 'vegetation', 'trunk', 'terrain', 'pole',
                    'traffic-sign'
                ],
                with_label=False),
            dict(
                type='Collect3D',
                keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
                meta_keys=[
                    'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
                ])
        ],
        classes=[
            'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
            'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
            'parking', 'sidewalk', 'other-ground', 'building', 'fence',
            'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR',
        split='test',
        camera_used=['left', 'right'],
        lidar_used=True,
        occ_size=[256, 256, 32],
        pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    shuffler_sampler=dict(type='DistributedGroupSampler'),
    nonshuffler_sampler=dict(type='DistributedSampler'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=4,
            use_dim=4),
        dict(
            type='LoadMultiViewImageFromFiles_SemanticKitti',
            is_train=False,
            data_config=dict(
                input_size=(384, 1280),
                resize=(0, 0),
                rot=(0, 0),
                flip=False,
                crop_h=(0.0, 0.0),
                resize_test=0.0),
            img_norm_cfg=dict(
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True)),
        dict(
            type='LoadSemKittiAnnotation',
            bda_aug_conf=dict(
                rot_lim=(0, 0),
                scale_lim=(1, 1),
                flip_dx_ratio=0,
                flip_dy_ratio=0,
                flip_dz_ratio=0),
            is_train=False,
            point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
            cls_metas='projects/configs/_base_/semantickitti.yaml'),
        dict(
            type='OccDefaultFormatBundle3D',
            class_names=[
                'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
                'parking', 'sidewalk', 'other-ground', 'building', 'fence',
                'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
            ],
            with_label=False),
        dict(
            type='Collect3D',
            keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
            meta_keys=[
                'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
            ])
    ],
    save_best='semkitti_SSC_mIoU',
    rule='greater')
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/scale_multi_kitti'
load_from = None
resume_from = None
workflow = [('train', 1)]
sync_bn = True
plugin = True
plugin_dir = 'projects/mmdet3d_plugin/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
camera_used = ['left', 'right']
num_class = 20
occ_size = [256, 256, 32]
lss_downsample = [2, 2, 2]
voxel_x = 0.2
voxel_y = 0.2
voxel_z = 0.2
voxel_size = [0.2, 0.2, 0.2]
pts_voxel_size = [0.05, 0.05, 0.05]
data_config = dict(
    input_size=(384, 1280),
    resize=(0, 0),
    rot=(0, 0),
    flip=False,
    crop_h=(0.0, 0.0),
    resize_test=0.0)
scale = 8
grid_config = dict(
    xbound=[0, 51.2, 0.4],
    ybound=[-25.6, 25.6, 0.4],
    zbound=[-2, 4.4, 0.4],
    dbound=[2.0, 58.0, 0.5])
numC_Trans = 128
voxel_channels = [128, 256, 512, 1024]
voxel_num_layer = [2, 2, 2, 2]
voxel_strides = [1, 2, 2, 2]
voxel_out_indices = (0, 1, 2, 3)
voxel_out_channels = 192
norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)
mask2former_num_queries = 100
mask2former_feat_channel = 192
mask2former_output_channel = 192
mask2former_pos_channel = 64.0
mask2former_num_heads = 6
empty_idx = 0
num_cls = 20
visible_mask = False
cascade_ratio = 2
sample_from_voxel = True
sample_from_img = True
model = dict(
    type='MoEOccupancyScale',
    loss_norm=False,
    voxel_size=[0.2, 0.2, 0.2],
    n_voxels=[256, 256, 32],
    aabb=([0, -25.6, -2], [51.2, 25.6, 4.4]),
    near_far_range=[0.2, 51.2],
    N_samples=64,
    N_rand=2048,
    depth_supervise=True,
    use_nerf_mask=True,
    nerf_sample_view=6,
    squeeze_scale=4,
    scale=8,
    nerf_density=True,
    use_rendering=True,
    test_rendering=False,
    loss_voxel_ce_weight=1.0,
    loss_voxel_sem_scal_weight=1.0,
    loss_voxel_geo_scal_weight=1.0,
    loss_voxel_lovasz_weight=1.0,
    img_backbone=dict(
        pretrained='ckpts/resnet50-0676ba61.pth',
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=0,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=False,
        style='pytorch'),
    img_neck=dict(
        type='SECONDFPN',
        in_channels=[256, 512, 1024, 2048],
        upsample_strides=[0.25, 0.5, 1, 2],
        out_channels=[128, 128, 128, 128]),
    img_view_transformer=dict(
        type='ViewTransformerLiftSplatShootVoxel',
        numC_input=512,
        cam_channels=33,
        scale=8,
        loss_depth_weight=1.0,
        grid_config=dict(
            xbound=[0, 51.2, 0.4],
            ybound=[-25.6, 25.6, 0.4],
            zbound=[-2, 4.4, 0.4],
            dbound=[2.0, 58.0, 0.5]),
        data_config=dict(
            input_size=(384, 1280),
            resize=(0, 0),
            rot=(0, 0),
            flip=False,
            crop_h=(0.0, 0.0),
            resize_test=0.0),
        numC_Trans=128,
        vp_megvii=False),
    pts_voxel_layer=dict(
        max_num_points=20,
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
        voxel_size=[0.05, 0.05, 0.05],
        max_voxels=(90000, 120000)),
    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),
    pts_middle_encoder=dict(
        type='SparseLiDAREnc8x',
        input_channel=4,
        base_channel=16,
        out_channel=128,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        sparse_shape_xyz=[1024, 1024, 128]),
    pts_backbone=dict(
        type='SECOND3D',
        in_channels=[128, 128, 128],
        out_channels=[128, 256, 512],
        layer_nums=[5, 5, 5],
        layer_strides=[1, 2, 4],
        is_cascade=False,
        norm_cfg=dict(type='BN3d', eps=0.001, momentum=0.01),
        conv_cfg=dict(type='Conv3d', kernel=(1, 3, 3), bias=False)),
    pts_neck=dict(
        type='SECOND3DFPN',
        in_channels=[128, 256, 512],
        out_channels=[128, 128, 128],
        upsample_strides=[1, 2, 4],
        norm_cfg=dict(type='BN3d', eps=0.001, momentum=0.01),
        upsample_cfg=dict(type='deconv3d', bias=False),
        extra_conv=dict(type='Conv3d', num_conv=3, bias=False),
        use_conv_for_no_stride=True),
    occ_fuser=dict(type='BiFuser', in_channels=128, out_channels=128),
    img_bev_encoder_backbone=dict(
        type='OccupancyEncoder',
        num_stage=4,
        in_channels=128,
        block_numbers=[2, 2, 2, 2],
        block_inplanes=[128, 256, 512, 1024],
        block_strides=[1, 2, 2, 2],
        out_indices=(0, 1, 2, 3),
        with_cp=True,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
    img_bev_encoder_neck=dict(
        type='MSDeformAttnPixelDecoder3D',
        strides=[2, 4, 8, 16],
        in_channels=[128, 256, 512, 1024],
        feat_channels=192,
        out_channels=192,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),
        encoder=dict(
            type='DetrTransformerEncoder',
            num_layers=6,
            transformerlayers=dict(
                type='BaseTransformerLayer',
                attn_cfgs=dict(
                    type='MultiScaleDeformableAttention3D',
                    embed_dims=192,
                    num_heads=8,
                    num_levels=3,
                    num_points=4,
                    im2col_step=64,
                    dropout=0.0,
                    batch_first=False,
                    norm_cfg=None,
                    init_cfg=None),
                ffn_cfgs=dict(embed_dims=192),
                feedforward_channels=768,
                ffn_dropout=0.0,
                operation_order=('self_attn', 'norm', 'ffn', 'norm')),
            init_cfg=None),
        positional_encoding=dict(
            type='SinePositionalEncoding3D', num_feats=64, normalize=True)),
    pts_bbox_head=dict(
        type='Mask2FormerOccHead',
        feat_channels=192,
        out_channels=192,
        num_queries=100,
        num_occupancy_classes=20,
        pooling_attn_mask=True,
        sample_weight_gamma=0.25,
        positional_encoding=dict(
            type='SinePositionalEncoding3D', num_feats=64.0, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=192,
                    num_heads=6,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=192,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True),
                feedforward_channels=1536,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1
            ]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0),
        point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4]),
    train_cfg=dict(
        pts=dict(
            num_points=50176,
            oversample_ratio=3.0,
            importance_sample_ratio=0.75,
            assigner=dict(
                type='MaskHungarianAssigner',
                cls_cost=dict(type='ClassificationCost', weight=2.0),
                mask_cost=dict(
                    type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
                dice_cost=dict(
                    type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
            sampler=dict(type='MaskPseudoSampler'))),
    test_cfg=dict(
        pts=dict(semantic_on=True, panoptic_on=False, instance_on=False)))
ann_file = 'data/SemanticKITTI/labels'
kitti_class_metas = 'projects/configs/_base_/semantickitti.yaml'
bda_aug_conf = dict(
    rot_lim=(0, 0),
    scale_lim=(1, 1),
    flip_dx_ratio=0,
    flip_dy_ratio=0,
    flip_dz_ratio=0)
test_config = dict(
    type='CustomSemanticKITTILssDataset_Scale',
    data_root='data/SemanticKITTI',
    ann_file='data/SemanticKITTI/labels',
    pipeline=[
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=4,
            use_dim=4),
        dict(
            type='LoadMultiViewImageFromFiles_SemanticKitti',
            is_train=False,
            data_config=dict(
                input_size=(384, 1280),
                resize=(0, 0),
                rot=(0, 0),
                flip=False,
                crop_h=(0.0, 0.0),
                resize_test=0.0),
            img_norm_cfg=dict(
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True)),
        dict(
            type='LoadSemKittiAnnotation',
            bda_aug_conf=dict(
                rot_lim=(0, 0),
                scale_lim=(1, 1),
                flip_dx_ratio=0,
                flip_dy_ratio=0,
                flip_dz_ratio=0),
            is_train=False,
            point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4],
            cls_metas='projects/configs/_base_/semantickitti.yaml'),
        dict(
            type='OccDefaultFormatBundle3D',
            class_names=[
                'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck',
                'other-vehicle', 'person', 'bicyclist', 'motorcyclist', 'road',
                'parking', 'sidewalk', 'other-ground', 'building', 'fence',
                'vegetation', 'trunk', 'terrain', 'pole', 'traffic-sign'
            ],
            with_label=False),
        dict(
            type='Collect3D',
            keys=['img_inputs', 'gt_occ', 'points', 'points_occ'],
            meta_keys=[
                'pc_range', 'occ_size', 'sequence', 'frame_id', 'raw_img'
            ])
    ],
    classes=[
        'unlabeled', 'car', 'bicycle', 'motorcycle', 'truck', 'other-vehicle',
        'person', 'bicyclist', 'motorcyclist', 'road', 'parking', 'sidewalk',
        'other-ground', 'building', 'fence', 'vegetation', 'trunk', 'terrain',
        'pole', 'traffic-sign'
    ],
    modality=dict(
        use_lidar=True,
        use_camera=True,
        use_radar=False,
        use_map=False,
        use_external=False),
    split='test',
    camera_used=['left', 'right'],
    lidar_used=True,
    occ_size=[256, 256, 32],
    pc_range=[0, -25.6, -2, 51.2, 25.6, 4.4])
embed_multi = dict(lr_mult=1.0, decay_mult=0.0)
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    weight_decay=0.01,
    eps=1e-08,
    betas=(0.9, 0.999),
    paramwise_cfg=dict(
        custom_keys=dict(
            query_embed=dict(lr_mult=1.0, decay_mult=0.0),
            query_feat=dict(lr_mult=1.0, decay_mult=0.0),
            level_embed=dict(lr_mult=1.0, decay_mult=0.0),
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0)),
        norm_decay_mult=0.0))
optimizer_config = dict(grad_clip=dict(max_norm=20, norm_type=2))
lr_config = dict(policy='step', step=[20, 25])
runner = dict(type='EpochBasedRunner', max_epochs=30)
gpu_ids = range(0, 8)

2023-10-28 00:30:21,412 - mmdet - INFO - Set random seed to 0, deterministic: False
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:342: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/backbones/resnet.py:400: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-28 00:30:22,691 - mmdet - INFO - initialize SECOND3D with init_cfg {'type': 'Kaiming', 'layer': 'Conv3d'}
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/necks/multi_scale_deform_attn_3d.py:141: UserWarning: You'd better set embed_dims in MultiScaleDeformAttention to make the dimension of each attention head a power of 2 which is more efficient in our CUDA implementation.
  "You'd better set embed_dims in "
2023-10-28 00:30:22,782 - mmdet - INFO - initialize SECOND3DFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-28 00:30:22,831 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'ckpts/resnet50-0676ba61.pth'}
2023-10-28 00:30:22,832 - mmcv - INFO - load model from: ckpts/resnet50-0676ba61.pth
2023-10-28 00:30:22,832 - mmcv - INFO - load checkpoint from local path: ckpts/resnet50-0676ba61.pth
2023-10-28 00:30:23,729 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2023-10-28 00:30:23,747 - mmdet - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
2023-10-28 00:30:23,845 - mmdet - INFO - Model:
MoEOccupancyScale(
  (pts_voxel_layer): Voxelization(voxel_size=[0.05, 0.05, 0.05], point_cloud_range=[0, -25.6, -2, 51.2, 25.6, 4.4], max_num_points=20, max_voxels=(90000, 120000), deterministic=True)
  (pts_voxel_encoder): HardSimpleVFE()
  (pts_middle_encoder): SparseLiDAREnc8x(
    (conv_input): SparseSequential(
      (0): SubMConv3d(4, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
      (1): GroupNorm(16, 16, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (2): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (conv2): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (2): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (conv3): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (2): SparseBasicBlock(
        (net): SparseSequential(
          (0): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (4): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (conv_out): SparseSequential(
      (0): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
      (1): GroupNorm(16, 128, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (pts_backbone): SECOND3D(
    (blocks): ModuleList(
      (0): Sequential(
        (0): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (7): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (10): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (13): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (16): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
        (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (4): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (7): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (10): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (13): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (16): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv3d(128, 512, kernel_size=(1, 3, 3), stride=(1, 4, 4), padding=(0, 1, 1), bias=False)
        (1): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (4): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (7): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (10): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (13): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (16): SyncBatchNorm(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Kaiming', 'layer': 'Conv3d'}
  (pts_neck): SECOND3DFPN(
    (deblocks): ModuleList(
      (0): Sequential(
        (0): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): ConvTranspose3d(256, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): ConvTranspose3d(512, 128, kernel_size=(1, 4, 4), stride=(1, 4, 4), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (extra_blocks): Sequential(
      (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (7): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  (pts_bbox_head): Mask2FormerOccHead(
    (transformer_decoder): DetrTransformerDecoder(
      (layers): ModuleList(
        (0): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (6): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (7): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (8): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=1536, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1536, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (post_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
    (decoder_input_projs): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Identity()
    )
    (decoder_positional_encoding): SinePositionalEncoding3D(num_feats=64.0, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (query_embed): Embedding(100, 192)
    (query_feat): Embedding(100, 192)
    (level_embed): Embedding(3, 192)
    (cls_embed): Linear(in_features=192, out_features=21, bias=True)
    (mask_embed): Sequential(
      (0): Linear(in_features=192, out_features=192, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=192, out_features=192, bias=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=192, out_features=192, bias=True)
    )
    (loss_cls): CrossEntropyLoss()
    (loss_mask): CrossEntropyLoss()
    (loss_dice): DiceLoss()
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'ckpts/resnet50-0676ba61.pth'}
  (img_neck): SECONDFPN(
    (deblocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(512, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): ConvTranspose2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (3): Sequential(
        (0): ConvTranspose2d(2048, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  (img_view_transformer): ViewTransformerLiftSplatShootVoxel(
    (depth_net): DepthNet(
      (reduce_conv): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (context_conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn): SyncBatchNorm(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (depth_mlp): Mlp(
        (fc1): Linear(in_features=33, out_features=512, bias=True)
        (act): ReLU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=512, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (depth_se): SELayer(
        (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (act1): ReLU()
        (conv_expand): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (gate): Sigmoid()
      )
      (context_mlp): Mlp(
        (fc1): Linear(in_features=33, out_features=512, bias=True)
        (act): ReLU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=512, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (context_se): SELayer(
        (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (act1): ReLU()
        (conv_expand): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (gate): Sigmoid()
      )
      (depth_conv): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): ASPP(
          (aspp1): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (aspp2): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (aspp3): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (aspp4): _ASPPModule(
            (atrous_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (global_avg_pool): Sequential(
            (0): AdaptiveAvgPool2d(output_size=(1, 1))
            (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): ReLU()
          )
          (conv1): Conv2d(2560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (dropout): Dropout(p=0.5, inplace=False)
        )
        (4): DeformConv2dPack(in_channels=512,
        out_channels=512,
        kernel_size=(3, 3),
        stride=(1, 1),
        padding=(1, 1),
        dilation=(1, 1),
        groups=4,
        deform_groups=1,
        bias=False)
        (5): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (img_bev_encoder_backbone): OccupancyEncoder(
    (layers): ModuleList(
      (0): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 128, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=128, out_features=128, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(16, 32, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(16, 32, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 128, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=128, out_features=128, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(16, 32, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(16, 32, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(16, 32, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
      (1): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Sequential(
            (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          )
          (input_conv): Sequential(
            (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=256, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=256, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 64, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(256, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=256, out_features=768, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=256, out_features=256, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=256, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=256, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 64, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 64, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(256, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
      (2): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Sequential(
            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (1): GroupNorm(32, 512, eps=1e-05, affine=True)
          )
          (input_conv): Sequential(
            (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 512, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=512, out_features=512, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 128, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 512, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(512, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 512, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=512, out_features=1536, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=512, out_features=512, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=512, out_features=512, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 128, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 128, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 512, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(512, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
      (3): Sequential(
        (0): DualpathTransformerBlock(
          (downsample): Sequential(
            (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
          )
          (input_conv): Sequential(
            (0): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 256, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(1024, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
        (1): DualpathTransformerBlock(
          (downsample): Identity()
          (input_conv): Sequential(
            (0): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (bev_encoder): SwinBlock(
            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (attn): ShiftWindowMSA(
              (w_msa): WindowMSA(
                (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop): DropPath()
            )
            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (ffn): FFN(
              (activate): GELU()
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU()
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): DropPath()
            )
          )
          (aspp): BottleNeckASPP(
            (input_conv): Sequential(
              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
            (aspp): ASPP(
              (aspp1): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp2): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp3): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (aspp4): _ASPPModule(
                (atrous_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
                (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
                (relu): ReLU(inplace=True)
              )
              (global_avg_pool): Sequential(
                (0): AdaptiveAvgPool2d(output_size=(1, 1))
                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (2): GroupNorm(32, 256, eps=1e-05, affine=True)
                (3): ReLU(inplace=True)
              )
              (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output_conv): Sequential(
              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): GroupNorm(32, 1024, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
            )
          )
          (combine_coeff): Conv3d(1024, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        )
      )
    )
  )
  (img_bev_encoder_neck): MSDeformAttnPixelDecoder3D(
    (input_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv3d(1024, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
      (1): ConvModule(
        (conv): Conv3d(512, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
      (2): ConvModule(
        (conv): Conv3d(256, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
    )
    (encoder): DetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention3D(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=192, out_features=288, bias=True)
              (attention_weights): Linear(in_features=192, out_features=96, bias=True)
              (value_proj): Linear(in_features=192, out_features=192, bias=True)
              (output_proj): Linear(in_features=192, out_features=192, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=192, out_features=768, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=768, out_features=192, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (postional_encoding): SinePositionalEncoding3D(num_feats=64, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (level_encoding): Embedding(3, 192)
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv3d(128, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
      )
    )
    (output_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)
        (activate): ReLU(inplace=True)
      )
    )
    (mask_feature): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  )
  (occ_fuser): BiFuser(
    (con_enc): Sequential(
      (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (4): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (knn_enc): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
    )
  )
  (color_head): MLP(
    (hidden_activation): ReLU()
    (output_activation): Identity()
    (hidden_layers): ModuleList(
      (0): Linear(in_features=192, out_features=256, bias=True)
      (1): Linear(in_features=256, out_features=256, bias=True)
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (posi_encoder): SinusoidalEncoder()
    (output_layer): Linear(in_features=256, out_features=3, bias=True)
  )
  (density_head): Linear(in_features=192, out_features=1, bias=True)
)
2023-10-28 00:30:33,466 - mmdet - INFO - Start running, host: jpan305@gpu1-34, work_dir: /hpc2hdd/home/jpan305/pytorch/MoEOccupancy/work_dirs/scale_multi_kitti
2023-10-28 00:30:33,466 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) OccDistEvalHook                    
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) OccDistEvalHook                    
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) OccDistEvalHook                    
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) OccDistEvalHook                    
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) OccDistEvalHook                    
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2023-10-28 00:30:33,466 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs
2023-10-28 00:30:33,466 - mmdet - INFO - Checkpoints will be saved to /hpc2hdd/home/jpan305/pytorch/MoEOccupancy/work_dirs/scale_multi_kitti by HardDiskBackend.
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
Traceback (most recent call last):
  File "tools/train.py", line 263, in <module>
    main()
  File "tools/train.py", line 259, in main
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/train.py", line 35, in custom_train_model
    meta=meta)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/apis/mmdet_train.py", line 199, in custom_train_detector
            runner.run(data_loaders, cfg.workflow)    runner.run(data_loaders, cfg.workflow)    runner.run(data_loaders, cfg.workflow)
        runner.run(data_loaders, cfg.workflow)    
runner.run(data_loaders, cfg.workflow)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
runner.run(data_loaders, cfg.workflow)runner.run(data_loaders, cfg.workflow)
runner.run(data_loaders, cfg.workflow)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run


  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
    epoch_runner(data_loaders[i], **kwargs)
      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train
        epoch_runner(data_loaders[i], **kwargs)epoch_runner(data_loaders[i], **kwargs)    epoch_runner(data_loaders[i], **kwargs)    
    
epoch_runner(data_loaders[i], **kwargs)
epoch_runner(data_loaders[i], **kwargs)      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train
epoch_runner(data_loaders[i], **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train

epoch_runner(data_loaders[i], **kwargs)    
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train

self.run_iter(data_batch, train_mode=True, **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train

      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
    self.run_iter(data_batch, train_mode=True, **kwargs)
        self.run_iter(data_batch, train_mode=True, **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
    self.run_iter(data_batch, train_mode=True, **kwargs)    

    self.run_iter(data_batch, train_mode=True, **kwargs)self.run_iter(data_batch, train_mode=True, **kwargs)self.run_iter(data_batch, train_mode=True, **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
**kwargs)


    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
**kwargs)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
    
      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
**kwargs)**kwargs)            

**kwargs)**kwargs)**kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step



      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
**kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
                output = self.module.train_step(*inputs[0], **kwargs[0])    output = self.module.train_step(*inputs[0], **kwargs[0])output = self.module.train_step(*inputs[0], **kwargs[0])output = self.module.train_step(*inputs[0], **kwargs[0])
    output = self.module.train_step(*inputs[0], **kwargs[0])    
    

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step
output = self.module.train_step(*inputs[0], **kwargs[0])
output = self.module.train_step(*inputs[0], **kwargs[0])  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step
output = self.module.train_step(*inputs[0], **kwargs[0])  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step


  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 237, in train_step
    losses = self(**data)    
    losses = self(**data)      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
losses = self(**data)
    losses = self(**data)            
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
losses = self(**data)
losses = self(**data)losses = self(**data)losses = self(**data)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl



  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)            
return forward_call(*input, **kwargs)        return forward_call(*input, **kwargs)    return forward_call(*input, **kwargs)      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func

return forward_call(*input, **kwargs)return forward_call(*input, **kwargs)
return forward_call(*input, **kwargs)
return forward_call(*input, **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func


  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward
    return old_func(*args, **kwargs)    
return old_func(*args, **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward
        return old_func(*args, **kwargs)    return old_func(*args, **kwargs)    
    return old_func(*args, **kwargs)
return old_func(*args, **kwargs)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward
return old_func(*args, **kwargs)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward


  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/mmdet3d-0.17.1-py3.7-linux-x86_64.egg/mmdet3d/models/detectors/base.py", line 59, in forward
                return self.forward_train(**kwargs)        return self.forward_train(**kwargs)return self.forward_train(**kwargs)    return self.forward_train(**kwargs)    
return self.forward_train(**kwargs)return self.forward_train(**kwargs)

return self.forward_train(**kwargs)
return self.forward_train(**kwargs)  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train


  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train

  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train

  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 328, in forward_train
    points, img=img_inputs, img_metas=img_metas)    
points, img=img_inputs, img_metas=img_metas)  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat

  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat
    points, img=img_inputs, img_metas=img_metas)
      File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat
        points, img=img_inputs, img_metas=img_metas)    points, img=img_inputs, img_metas=img_metas)    points, img=img_inputs, img_metas=img_metas)
points, img=img_inputs, img_metas=img_metas)
points, img=img_inputs, img_metas=img_metas)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat
    
      File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat

  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat
pts_voxel_feats, pts_feats = self.extract_pts_feat(points)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
pts_voxel_feats, pts_feats = self.extract_pts_feat(points)
      File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 234, in extract_feat
    pts_voxel_feats, pts_feats = self.extract_pts_feat(points)pts_voxel_feats, pts_feats = self.extract_pts_feat(points)

  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
              File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
pts_voxel_feats, pts_feats = self.extract_pts_feat(points)pts_voxel_feats, pts_feats = self.extract_pts_feat(points)pts_voxel_feats, pts_feats = self.extract_pts_feat(points)        


    x = self.pts_backbone(pts_enc_feats)x = self.pts_backbone(pts_enc_feats)  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
pts_voxel_feats, pts_feats = self.extract_pts_feat(points)
      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl

      File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl

x = self.pts_backbone(pts_enc_feats)x = self.pts_backbone(pts_enc_feats)      File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/detectors/moeoccupancyscale.py", line 212, in extract_pts_feat
    

x = self.pts_backbone(pts_enc_feats)    x = self.pts_backbone(pts_enc_feats)  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl

x = self.pts_backbone(pts_enc_feats)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl

  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    x = self.pts_backbone(pts_enc_feats)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
    return forward_call(*input, **kwargs)
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
    return forward_call(*input, **kwargs)
      File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
return forward_call(*input, **kwargs)
          File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
    return forward_call(*input, **kwargs)return forward_call(*input, **kwargs)return forward_call(*input, **kwargs)    


return forward_call(*input, **kwargs)  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward

  File "/hpc2hdd/home/jpan305/pytorch/MoEOccupancy/projects/mmdet3d_plugin/occformer/backbones/second3d.py", line 99, in forward
        batch = x.shape[0]batch = x.shape[0]
    
AttributeError    batch = x.shape[0]        :     batch = x.shape[0]    AttributeError
batch = x.shape[0]batch = x.shape[0]'dict' object has no attribute 'shape'batch = x.shape[0]
batch = x.shape[0]: 
AttributeError



AttributeError'dict' object has no attribute 'shape': AttributeErrorAttributeErrorAttributeError: 
'dict' object has no attribute 'shape'AttributeError: : : 'dict' object has no attribute 'shape'
: 'dict' object has no attribute 'shape''dict' object has no attribute 'shape''dict' object has no attribute 'shape'
'dict' object has no attribute 'shape'



ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 514655) of binary: /hpc2hdd/home/jpan305/miniconda3/envs/occ/bin/python
Traceback (most recent call last):
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/run.py", line 713, in run
    )(*cmd_args)
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/hpc2hdd/home/jpan305/miniconda3/envs/occ/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 261, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
tools/train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 514656)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 514657)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 514658)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 514659)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 514660)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 514661)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 514662)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-28_00:30:42
  host      : gpu1-34.hkust-gz.edu.cn
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 514655)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
